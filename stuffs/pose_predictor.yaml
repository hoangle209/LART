launcher: {}
trainer:
  _target_: pytorch_lightning.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 30
  accelerator: gpu
  devices: 8
  num_nodes: 1
  check_val_every_n_epoch: 1
  deterministic: false
  benchmark: true
  accumulate_grad_batches: 1
  gradient_clip_val: 2.0
  precision: 32
  num_sanity_val_steps: 0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  sync_batchnorm: true
  strategy: ddp
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: step
    mode: max
    save_last: true
    auto_insert_metric_name: false
    verbose: false
    save_top_k: -1
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: 1
    save_on_train_epoch_end: true
  model_summary:
    _target_: pytorch_lightning.callbacks.RichModelSummary
    max_depth: 1
  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.RichProgressBar
    refresh_rate: 1
  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
  timer:
    _target_: pytorch_lightning.callbacks.Timer
logger:
  tensorboard:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: ${paths.output_dir}/tensorboard/
    version: 0
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/logs2/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
extras:
  print_config: true
hydra_logging: colorlog
job_logging: colorlog
task_name: 40006
tags:
- dev
train: true
test: true
ckpt_path: null
seed: null
datamodule:
  _target_: src.datamodules.phalp_datamodule.PHALPDataModule
  cfg: ${configs}
  train: ${train}
model:
  _target_: src.models.bert_person_v2.BERT_PERSON_V2_LitModule
  cfg: ${configs}
configs:
  data_dir: ${paths.data_dir}
  storage_folder: ${paths.log_dir}/${task_name}/${hydra:sweep.subdir}
  train_dataset: kinetics_train_12,ava_train_12
  test_dataset: ava_val_12
  map_on: AVA
  train_batch_size: 8
  train_num_workers: 4
  test_batch_size: 8
  test_num_workers: 4
  test_class: ''
  test_batch_id: -1
  number_of_processes: 25
  pin_memory: true
  full_seq_render: false
  frame_length: 126
  max_people: 1
  load_other_tracks: false
  img_size: 256
  load_images: false
  use_mean_std: true
  use_mean_std_mid: false
  frame_rate_range: 1
  num_smpl_heads: 1
  finetune: false
  solver: AdamW
  lr: 0.001
  momentum: 0.9
  decay_steps:
  - 10
  - 20
  decay_gamma: 0.1
  layer_decay: null
  ZERO_WD_1D_PARAM: true
  warmup_epochs: 5
  weight_decay: 0.05
  scheduler: cosine
  bottle_neck: conv_11
  pos_embedding: learned
  mask_ratio: 0.6
  in_feat: 256
  one_euro_filter: pred_loca,pred_pose
  loss_type: pose_l2,loca_l1
  mask_type: random_y
  mask_type_test: zero
  test_type: track.fullframe|
  encode_type: 4c
  masked: true
  masked_mvit: false
  wights_path: null
  use_rakel: false
  use_relative_pose: false
  use_optimized_pose: false
  loss_on_others_action: true
  debug: false
  store_svm_vectors: false
  svm_folder: ''
  full_gt_supervision: 0
  full_pesudo_supervision: 0
  full_pesudo_supervision_c1: 0.2
  load_strict: true
  mixed_training: 0
  compute_map: false
  compute_acc: true
  save_eval_pkl: true
  log_frequency: 100
  hmr_model: hmr2023
  th_ava: 0.0
  dataset_loader: fast
  action_space: ava
  ava:
    sampling_factor: 1
    num_action_classes: 80
    num_valid_action_classes: 60
    gt_type: all
    head_dropout: 0.0
    predict_valid: true
    distil_type: both_bce
  kinetics:
    sampling_factor: 1
    num_action_classes: 400
  loss:
    focal:
      gamma: 2
      alpha: 0.25
  extra_feat:
    enable: ''
    pose_shape:
      dim: 229
      mid_dim: 229
      en_dim: 256
    appe:
      dim: 4096
      mid_dim: 1024
      en_dim: 256
    action:
      dim: 80
      mid_dim: 128
      en_dim: 256
    mvit:
      dim: 1152
      mid_dim: 1024
      en_dim: 1024
    hmr:
      dim: 2048
      mid_dim: 1024
      en_dim: 256
    objects:
      dim: 80
      mid_dim: 128
      en_dim: 256
    clip:
      dim: 512
      mid_dim: 128
      en_dim: 256
    vitpose:
      dim: 75
      mid_dim: 128
      en_dim: 256
    joints_3D:
      dim: 135
      mid_dim: 256
      en_dim: 128
    relative_pose:
      dim: 16
      mid_dim: 128
      en_dim: 256
    Dpose:
      dim: 229
      mid_dim: 256
      en_dim: 256
    img:
      dim: 512
      mid_dim: 256
      en_dim: 256
    mae_emb:
      dim: 1280
      mid_dim: 1024
      en_dim: 512
  render:
    enable: true
    engine: PYR
    num_videos: 1
    vis_pred_loca: true
    vis_action_label: person
    res: 256
    render_up_scale: 2
    walker: SMPL+B
  transformer:
    depth: 6
    heads: 8
    mlp_dim: 512
    dim_head: 64
    dropout: 0.1
    emb_dropout: 0.1
    droppath: 0.1
    use_interaction_module: false
    use_perceiver: false
    use_interaction_module_action_only: false
    conv:
      pad: 1
      stride: 9
    perceiver:
      num_of_latents: 32
      latent_dim: 128
      cross_heads: 1
      cross_dim_head: 64
      latent_dim_head: 64
      attn_dropout: 0.0
      ff_dropout: 0.0
      self_per_cross_attn: 1
      latent_heads: 8
  smpl_cfg:
    SMPL:
      MODEL_PATH: data/3D
      GENDER: neutral
      MODEL_TYPE: smpl
      NUM_BODY_JOINTS: 23
      JOINT_REGRESSOR_H36M: data/3D/J_regressor_h36m.npy
      JOINT_REGRESSOR_EXTRA: data/3D/SMPL_to_J19.pkl
      TEXTURE: data/3D/texture.npz
    MODEL:
      IMAGE_SIZE: 256
      SMPL_HEAD:
        TYPE: basic
        POOL: max
        SMPL_MEAN_PARAMS: data/3D/smpl_mean_params.npz
        IN_CHANNELS: 2048
      BACKBONE:
        TYPE: resnet
        NUM_LAYERS: 50
    EXTRA:
      FOCAL_LENGTH: 5000
